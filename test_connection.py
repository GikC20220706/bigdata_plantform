#!/usr/bin/env python3
"""
æœåŠ¡å™¨è¿æ¥æµ‹è¯•å·¥å…·
ç”¨äºè¯Šæ–­å’ŒéªŒè¯ä¸hadoop101æœåŠ¡å™¨çš„è¿æ¥
"""

import socket
import requests
import subprocess
import sys
from pathlib import Path
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))


def test_hostname_resolution():
    """æµ‹è¯•ä¸»æœºåè§£æ"""
    print("ğŸ” æµ‹è¯•ä¸»æœºåè§£æ...")

    try:
        import socket
        ip = socket.gethostbyname('hadoop101')
        print(f"âœ… hadoop101 è§£æä¸º: {ip}")
        return ip
    except socket.gaierror:
        print("âŒ æ— æ³•è§£æ hadoop101 ä¸»æœºå")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("1. è·å–æœåŠ¡å™¨IPåœ°å€")
        print("2. åœ¨ C:\\Windows\\System32\\drivers\\etc\\hosts æ–‡ä»¶ä¸­æ·»åŠ :")
        print("   YOUR_SERVER_IP hadoop101")
        print("3. æˆ–ç›´æ¥åœ¨.envä¸­ä½¿ç”¨IPåœ°å€æ›¿æ¢hadoop101")
        return None


def test_port_connectivity(host, ports):
    """æµ‹è¯•ç«¯å£è¿é€šæ€§"""
    print(f"\nğŸ”Œ æµ‹è¯• {host} ç«¯å£è¿é€šæ€§...")

    results = {}
    for service, port in ports.items():
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            result = sock.connect_ex((host, port))
            sock.close()

            if result == 0:
                print(f"âœ… {service} ({port}): è¿æ¥æˆåŠŸ")
                results[service] = True
            else:
                print(f"âŒ {service} ({port}): è¿æ¥å¤±è´¥")
                results[service] = False
        except Exception as e:
            print(f"âŒ {service} ({port}): æµ‹è¯•å¼‚å¸¸ - {e}")
            results[service] = False

    return results


def test_web_services(host):
    """æµ‹è¯•WebæœåŠ¡å¯è®¿é—®æ€§"""
    print(f"\nğŸŒ æµ‹è¯• {host} WebæœåŠ¡...")

    web_services = {
        "HDFS NameNode WebUI": f"http://{host}:9870",
        "Flink JobManager WebUI": f"http://{host}:8081",
        "Doris Frontend WebUI": f"http://{host}:8060"
    }

    results = {}
    for service, url in web_services.items():
        try:
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                print(f"âœ… {service}: å¯è®¿é—® ({response.status_code})")
                results[service] = True
            else:
                print(f"âš ï¸ {service}: HTTP {response.status_code}")
                results[service] = False
        except requests.exceptions.RequestException:
            print(f"âŒ {service}: è¿æ¥è¢«æ‹’ç»")
            results[service] = False
        except requests.exceptions.Timeout:
            print(f"âŒ {service}: è¿æ¥è¶…æ—¶")
            results[service] = False
        except Exception as e:
            print(f"âŒ {service}: è®¿é—®å¼‚å¸¸ - {e}")
            results[service] = False

    return results


def test_hive_connection():
    """æµ‹è¯•Hiveè¿æ¥"""
    print("\nğŸ æµ‹è¯•Hiveè¿æ¥...")

    try:
        # å°è¯•å¯¼å…¥pyhive
        from pyhive import hive
        print("âœ… pyhive åº“å·²å®‰è£…")

        # å°è¯•è¿æ¥
        try:
            conn = hive.Connection(
                host='hadoop101',
                port=10000,
                username='bigdata',
                password='gqdw8862',
                auth='CUSTOM'
            )

            cursor = conn.cursor()
            cursor.execute("SHOW DATABASES")
            databases = cursor.fetchall()

            print(f"âœ… Hiveè¿æ¥æˆåŠŸï¼æ‰¾åˆ° {len(databases)} ä¸ªæ•°æ®åº“:")
            for db in databases[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                print(f"   - {db[0]}")

            if len(databases) > 5:
                print(f"   ... è¿˜æœ‰ {len(databases) - 5} ä¸ªæ•°æ®åº“")

            cursor.close()
            conn.close()
            return True

        except Exception as e:
            print(f"âŒ Hiveè¿æ¥å¤±è´¥: {e}")
            return False

    except ImportError:
        print("âŒ pyhive åº“æœªå®‰è£…")
        print("ğŸ’¡ å®‰è£…å‘½ä»¤: pip install pyhive[hive] sasl thrift thrift-sasl")
        return False


def test_hdfs_connection():
    """æµ‹è¯•HDFSè¿æ¥"""
    print("\nğŸ“ æµ‹è¯•HDFSè¿æ¥...")

    # æµ‹è¯•WebHDFS API
    try:
        webhdfs_url = "http://hadoop101:9870/webhdfs/v1/?op=LISTSTATUS"
        response = requests.get(webhdfs_url, timeout=10)

        if response.status_code == 200:
            data = response.json()
            if 'FileStatuses' in data:
                print("âœ… HDFS WebHDFS API è¿æ¥æˆåŠŸ")
                files = data['FileStatuses']['FileStatus']
                print(f"   æ ¹ç›®å½•åŒ…å« {len(files)} ä¸ªæ–‡ä»¶/ç›®å½•")
                return True
            else:
                print(f"âš ï¸ HDFS WebHDFS API å“åº”å¼‚å¸¸: {data}")
                return False
        else:
            print(f"âŒ HDFS WebHDFS API HTTP {response.status_code}")
            return False

    except Exception as e:
        print(f"âŒ HDFSè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False


def generate_hosts_file_entry():
    """ç”Ÿæˆhostsæ–‡ä»¶æ¡ç›®"""
    print("\nğŸ“ å¦‚æœä¸»æœºåè§£æå¤±è´¥ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œ:")
    print("1. åœ¨æœåŠ¡å™¨ä¸Šæ‰§è¡Œå‘½ä»¤è·å–IPåœ°å€:")
    print("   ip addr show | grep 'inet ' | grep -v '127.0.0.1'")
    print("\n2. ç¼–è¾‘Windows hostsæ–‡ä»¶:")
    print("   æ–‡ä»¶ä½ç½®: C:\\Windows\\System32\\drivers\\etc\\hosts")
    print("   æ·»åŠ è¡Œ: YOUR_SERVER_IP hadoop101")
    print("\n3. æˆ–è€…ç›´æ¥åœ¨.envæ–‡ä»¶ä¸­ä½¿ç”¨IPåœ°å€æ›¿æ¢hadoop101")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª é¦–ä¿¡äº‘æ•°æ®åº•åº§ - æœåŠ¡å™¨è¿æ¥è¯Šæ–­å·¥å…·")
    print("=" * 60)

    # 1. æµ‹è¯•ä¸»æœºåè§£æ
    server_ip = test_hostname_resolution()

    if not server_ip:
        generate_hosts_file_entry()
        return

    # 2. æµ‹è¯•ç«¯å£è¿é€šæ€§
    ports = {
        "HDFS NameNode RPC": 8020,
        "HDFS NameNode WebUI": 9870,
        "Hive Server2": 10000,
        "Flink JobManager": 8081,
        "Doris Frontend": 8060,
        "Redis": 6379
    }

    port_results = test_port_connectivity('hadoop101', ports)

    # 3. æµ‹è¯•WebæœåŠ¡
    web_results = test_web_services('hadoop101')

    # 4. æµ‹è¯•Hiveè¿æ¥
    hive_result = test_hive_connection()

    # 5. æµ‹è¯•HDFSè¿æ¥
    hdfs_result = test_hdfs_connection()

    # 6. ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
    print("\nğŸ“Š è¿æ¥è¯Šæ–­æŠ¥å‘Š")
    print("=" * 40)

    print(f"ä¸»æœºåè§£æ: {'âœ… æˆåŠŸ' if server_ip else 'âŒ å¤±è´¥'}")

    successful_ports = sum(1 for success in port_results.values() if success)
    total_ports = len(port_results)
    print(f"ç«¯å£è¿é€šæ€§: {successful_ports}/{total_ports} æˆåŠŸ")

    successful_web = sum(1 for success in web_results.values() if success)
    total_web = len(web_results)
    print(f"WebæœåŠ¡: {successful_web}/{total_web} å¯è®¿é—®")

    print(f"Hiveè¿æ¥: {'âœ… æˆåŠŸ' if hive_result else 'âŒ å¤±è´¥'}")
    print(f"HDFSè¿æ¥: {'âœ… æˆåŠŸ' if hdfs_result else 'âŒ å¤±è´¥'}")

    # 7. æä¾›å»ºè®®
    print("\nğŸ’¡ å»ºè®®:")
    if not server_ip:
        print("- é¦–å…ˆè§£å†³ä¸»æœºåè§£æé—®é¢˜")
    elif successful_ports < total_ports:
        print("- æ£€æŸ¥æœåŠ¡å™¨é˜²ç«å¢™è®¾ç½®")
        print("- ç¡®è®¤æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ")
    elif not hive_result:
        print("- å®‰è£…Hiveå®¢æˆ·ç«¯ä¾èµ–: pip install pyhive[hive]")
        print("- æ£€æŸ¥Hiveç”¨æˆ·åå¯†ç ")
    elif successful_ports == total_ports and hive_result:
        print("- âœ… è¿æ¥é…ç½®æ­£ç¡®ï¼Œå¯ä»¥å¯åŠ¨åº”ç”¨ï¼")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ›‘ æµ‹è¯•å·²å–æ¶ˆ")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºé”™: {e}")