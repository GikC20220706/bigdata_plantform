# test_overview_endpoints.py
import asyncio
import requests
import json
from datetime import datetime

BASE_URL = "http://localhost:8000"  # ä¿®æ”¹ä¸ºä½ çš„FastAPIæœåŠ¡åœ°å€


def test_overview_endpoints():
    """æµ‹è¯•æ‰€æœ‰Overviewç›¸å…³çš„APIç«¯ç‚¹"""
    print("=== æµ‹è¯•Overview APIç«¯ç‚¹ (ä½¿ç”¨çœŸå®é›†ç¾¤æ•°æ®) ===")

    endpoints = [
        {"url": "/api/overview/", "name": "æ•°æ®æ€»è§ˆ"},
        {"url": "/api/overview/stats", "name": "ç»Ÿè®¡ä¿¡æ¯"},
        {"url": "/api/overview/clusters", "name": "é›†ç¾¤çŠ¶æ€"},
        {"url": "/api/overview/clusters/real-time", "name": "å®æ—¶é›†ç¾¤æŒ‡æ ‡"},
        {"url": "/api/overview/tasks/today", "name": "ä»Šæ—¥ä»»åŠ¡"},
        {"url": "/api/overview/storage", "name": "å­˜å‚¨ä¿¡æ¯"},
        {"url": "/api/overview/quality", "name": "æ•°æ®è´¨é‡æŒ‡æ ‡"},
        {"url": "/api/overview/health", "name": "ç³»ç»Ÿå¥åº·çŠ¶æ€"},
        {"url": "/api/overview/business-systems", "name": "ä¸šåŠ¡ç³»ç»Ÿåˆ—è¡¨"},
        {"url": "/api/overview/database-layers", "name": "æ•°æ®åº“åˆ†å±‚ç»Ÿè®¡"}
    ]

    results = []

    for endpoint in endpoints:
        print(f"\n{'=' * 60}")
        print(f"æµ‹è¯•: {endpoint['name']}")
        print(f"URL: {endpoint['url']}")

        try:
            response = requests.get(f"{BASE_URL}{endpoint['url']}", timeout=30)

            if response.status_code == 200:
                data = response.json()
                print(f"âœ… è¯·æ±‚æˆåŠŸ (çŠ¶æ€ç : {response.status_code})")

                # åˆ†æå“åº”æ•°æ®
                result = analyze_response(endpoint, data)
                results.append(result)

                # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
                display_key_info(endpoint, data)

            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥ (çŠ¶æ€ç : {response.status_code})")
                try:
                    error_data = response.json()
                    print(f"é”™è¯¯è¯¦æƒ…: {error_data}")
                except:
                    print(f"é”™è¯¯å“åº”: {response.text}")

        except requests.exceptions.Timeout:
            print("âŒ è¯·æ±‚è¶…æ—¶")
        except requests.exceptions.ConnectionError:
            print("âŒ è¿æ¥å¤±è´¥ - è¯·ç¡®ä¿FastAPIæœåŠ¡æ­£åœ¨è¿è¡Œ")
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}")

    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    generate_test_report(results)


def analyze_response(endpoint, data):
    """åˆ†æå“åº”æ•°æ®"""
    result = {
        "endpoint": endpoint['name'],
        "url": endpoint['url'],
        "success": True,
        "data_sources": [],
        "real_data_count": 0,
        "mock_data_count": 0,
        "error_count": 0,
        "key_metrics": {}
    }

    # é€’å½’æŸ¥æ‰¾æ•°æ®æºä¿¡æ¯
    data_sources = find_data_sources(data)
    result["data_sources"] = data_sources

    # ç»Ÿè®¡æ•°æ®æºç±»å‹
    for source in data_sources:
        if source == "real":
            result["real_data_count"] += 1
        elif source == "mock":
            result["mock_data_count"] += 1
        elif source == "error":
            result["error_count"] += 1

    return result


def find_data_sources(obj, sources=None):
    """é€’å½’æŸ¥æ‰¾data_sourceå­—æ®µ"""
    if sources is None:
        sources = []

    if isinstance(obj, dict):
        if "data_source" in obj:
            sources.append(obj["data_source"])
        for value in obj.values():
            find_data_sources(value, sources)
    elif isinstance(obj, list):
        for item in obj:
            find_data_sources(item, sources)

    return sources


def display_key_info(endpoint, data):
    """æ˜¾ç¤ºå…³é”®ä¿¡æ¯"""
    if endpoint['name'] == "æ•°æ®æ€»è§ˆ":
        if 'clusters' in data:
            clusters = data['clusters']
            print(f"   ğŸ“Š é›†ç¾¤æ•°é‡: {len(clusters)}")
            for cluster in clusters:
                status = cluster.get('status', 'unknown')
                nodes = f"{cluster.get('active_nodes', 0)}/{cluster.get('total_nodes', 0)}"
                data_source = cluster.get('data_source', 'unknown')
                print(f"      - {cluster.get('name', 'Unknown')}: {status} ({nodes} èŠ‚ç‚¹) [{data_source}]")

    elif endpoint['name'] == "é›†ç¾¤çŠ¶æ€":
        if 'data' in data:
            clusters = data['data']
            print(f"   ğŸ“Š é›†ç¾¤çŠ¶æ€è¯¦æƒ…:")
            for cluster in clusters:
                name = cluster.get('name', 'Unknown')
                status = cluster.get('status', 'unknown')
                cpu = cluster.get('cpu_usage', 0)
                memory = cluster.get('memory_usage', 0)
                data_source = cluster.get('data_source', 'unknown')
                print(f"      - {name}: {status} (CPU: {cpu}%, Memory: {memory}%) [{data_source}]")

    elif endpoint['name'] == "å®æ—¶é›†ç¾¤æŒ‡æ ‡":
        if 'data' in data:
            clusters_data = data['data']
            print(f"   âš¡ å®æ—¶æŒ‡æ ‡:")
            for cluster_type, metrics in clusters_data.items():
                name = metrics.get('cluster_name', cluster_type)
                health = metrics.get('health_score', 0)
                nodes = f"{metrics.get('active_nodes', 0)}/{metrics.get('total_nodes', 0)}"
                data_source = metrics.get('data_source', 'unknown')
                print(f"      - {name}: å¥åº·åº¦ {health}% ({nodes} èŠ‚ç‚¹) [{data_source}]")

    elif endpoint['name'] == "ç³»ç»Ÿå¥åº·çŠ¶æ€":
        if 'overall_status' in data:
            overall = data['overall_status']
            components = data.get('components', {})
            alerts = data.get('alerts', [])
            print(f"   ğŸ¥ æ€»ä½“çŠ¶æ€: {overall}")
            print(f"   ğŸ” ç»„ä»¶çŠ¶æ€:")
            for comp_name, comp_data in components.items():
                status = comp_data.get('status', 'unknown')
                message = comp_data.get('message', 'No message')
                data_source = comp_data.get('data_source', 'unknown')
                print(f"      - {comp_name}: {status} - {message} [{data_source}]")
            if alerts:
                print(f"   âš ï¸ æ´»è·ƒå‘Šè­¦: {len(alerts)} ä¸ª")

    elif endpoint['name'] == "ä»Šæ—¥ä»»åŠ¡":
        if 'data' in data:
            task_data = data['data']
            if 'tasks' in task_data:
                tasks = task_data['tasks']
                cluster_status = task_data.get('cluster_status', {})
                print(f"   ğŸ“‹ ä»Šæ—¥ä»»åŠ¡: {len(tasks)} ä¸ª")
                print(f"   ğŸ”„ è¿è¡Œä¸­: {task_data.get('running_tasks', 0)} ä¸ª")
                print(f"   âœ… å·²å®Œæˆ: {task_data.get('completed_tasks', 0)} ä¸ª")
                print(f"   âŒ å¤±è´¥: {task_data.get('failed_tasks', 0)} ä¸ª")
                print(f"   ğŸ–¥ï¸ é›†ç¾¤çŠ¶æ€:")
                for cluster, status in cluster_status.items():
                    healthy = "å¥åº·" if status.get('healthy') else "å¼‚å¸¸"
                    nodes = f"{status.get('active_nodes', 0)}/{status.get('total_nodes', 0)}"
                    print(f"      - {cluster}: {healthy} ({nodes} èŠ‚ç‚¹)")

    elif endpoint['name'] == "æ•°æ®è´¨é‡æŒ‡æ ‡":
        if 'overall_score' in data:
            score = data['overall_score']
            completeness = data.get('completeness', 0)
            accuracy = data.get('accuracy', 0)
            consistency = data.get('consistency', 0)
            timeliness = data.get('timeliness', 0)
            print(f"   â­ æ€»ä½“è¯„åˆ†: {score}%")
            print(f"   ğŸ“Š è¯¦ç»†æŒ‡æ ‡:")
            print(f"      - å®Œæ•´æ€§: {completeness}%")
            print(f"      - å‡†ç¡®æ€§: {accuracy}%")
            print(f"      - ä¸€è‡´æ€§: {consistency}%")
            print(f"      - åŠæ—¶æ€§: {timeliness}%")


def generate_test_report(results):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print(f"\n{'=' * 60}")
    print("=== æµ‹è¯•æŠ¥å‘Š ===")

    total_tests = len(results)
    successful_tests = len([r for r in results if r['success']])

    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"æˆåŠŸ: {successful_tests}")
    print(f"å¤±è´¥: {total_tests - successful_tests}")

    # æ•°æ®æºç»Ÿè®¡
    total_real_data = sum(r['real_data_count'] for r in results)
    total_mock_data = sum(r['mock_data_count'] for r in results)
    total_error_data = sum(r['error_count'] for r in results)

    print(f"\næ•°æ®æºåˆ†æ:")
    print(f"ä½¿ç”¨çœŸå®æ•°æ®: {total_real_data} ä¸ªæ•°æ®ç‚¹")
    print(f"ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {total_mock_data} ä¸ªæ•°æ®ç‚¹")
    print(f"æ•°æ®é”™è¯¯: {total_error_data} ä¸ªæ•°æ®ç‚¹")

    # è¯¦ç»†ç»“æœ
    print(f"\nè¯¦ç»†ç»“æœ:")
    for result in results:
        endpoint_name = result['endpoint']
        real_count = result['real_data_count']
        mock_count = result['mock_data_count']
        error_count = result['error_count']

        status_icon = "âœ…" if result['success'] else "âŒ"
        data_status = ""

        if real_count > 0 and mock_count == 0 and error_count == 0:
            data_status = "ğŸŸ¢ å…¨éƒ¨çœŸå®æ•°æ®"
        elif real_count > 0 and (mock_count > 0 or error_count > 0):
            data_status = "ğŸŸ¡ æ··åˆæ•°æ®"
        elif mock_count > 0 and real_count == 0:
            data_status = "ğŸ”µ æ¨¡æ‹Ÿæ•°æ®"
        elif error_count > 0:
            data_status = "ğŸ”´ æ•°æ®é”™è¯¯"
        else:
            data_status = "âšª æ— æ•°æ®æºä¿¡æ¯"

        print(f"  {status_icon} {endpoint_name}: {data_status}")

    # å»ºè®®
    print(f"\nå»ºè®®:")
    if total_real_data == 0:
        print("- â— æ‰€æœ‰APIéƒ½åœ¨ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œè¯·æ£€æŸ¥:")
        print("  1. .env é…ç½®: IS_LOCAL_DEV=false, MOCK_DATA_MODE=false")
        print("  2. SSHè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("  3. metrics_collector æ˜¯å¦æ­£å¸¸å·¥ä½œ")
    elif total_mock_data > 0:
        print("- âš ï¸ éƒ¨åˆ†APIä»åœ¨ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œå¯èƒ½åŸå› :")
        print("  1. éƒ¨åˆ†é›†ç¾¤èŠ‚ç‚¹è¿æ¥å¤±è´¥")
        print("  2. æŸäº›æœåŠ¡ç»„ä»¶å¼‚å¸¸")
    else:
        print("- ğŸ‰ æ‰€æœ‰APIéƒ½åœ¨ä½¿ç”¨çœŸå®æ•°æ®ï¼Œç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼")

    if total_error_data > 0:
        print(f"- ğŸš¨ å‘ç° {total_error_data} ä¸ªæ•°æ®é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ’æŸ¥é—®é¢˜")


def test_refresh_endpoint():
    """æµ‹è¯•åˆ·æ–°ç«¯ç‚¹"""
    print(f"\n{'=' * 60}")
    print("æµ‹è¯•æ•°æ®åˆ·æ–°åŠŸèƒ½...")

    try:
        response = requests.post(f"{BASE_URL}/api/overview/refresh", timeout=30)

        if response.status_code == 200:
            data = response.json()
            print("âœ… æ•°æ®åˆ·æ–°æˆåŠŸ")

            if 'data' in data:
                refresh_data = data['data']
                print(f"   åˆ·æ–°æ—¶é—´: {refresh_data.get('refresh_time', 'Unknown')}")
                print(f"   é›†ç¾¤æ•°é‡: {refresh_data.get('clusters_count', 0)}")
                print(f"   çœŸå®æ•°æ®é›†ç¾¤: {refresh_data.get('real_data_clusters', 0)}")

                cluster_summary = refresh_data.get('cluster_summary', {})
                print(f"   é›†ç¾¤çŠ¶æ€:")
                for cluster_type, info in cluster_summary.items():
                    nodes = f"{info.get('active_nodes', 0)}/{info.get('total_nodes', 0)}"
                    data_source = info.get('data_source', 'unknown')
                    print(f"     - {cluster_type}: {nodes} èŠ‚ç‚¹ [{data_source}]")
        else:
            print(f"âŒ åˆ·æ–°å¤±è´¥ (çŠ¶æ€ç : {response.status_code})")

    except Exception as e:
        print(f"âŒ åˆ·æ–°å¼‚å¸¸: {str(e)}")


async def test_direct_metrics():
    """ç›´æ¥æµ‹è¯•metrics_collector"""
    print(f"\n{'=' * 60}")
    print("ç›´æ¥æµ‹è¯• metrics_collector...")

    try:
        import sys
        import os
        sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

        from app.utils.metrics_collector import metrics_collector

        for cluster_type in ['hadoop', 'flink', 'doris']:
            print(f"\næµ‹è¯• {cluster_type} é›†ç¾¤...")
            try:
                cluster_metrics = await metrics_collector.get_cluster_metrics(cluster_type)

                data_source = cluster_metrics.get('data_source', 'unknown')
                active_nodes = cluster_metrics.get('active_nodes', 0)
                total_nodes = cluster_metrics.get('total_nodes', 0)
                cpu_usage = cluster_metrics.get('cpu_usage', 0)
                memory_usage = cluster_metrics.get('memory_usage', 0)

                print(f"âœ… {cluster_type} - æ•°æ®æº: {data_source}")
                print(f"   èŠ‚ç‚¹: {active_nodes}/{total_nodes}")
                print(f"   CPU: {cpu_usage}%, Memory: {memory_usage}%")

            except Exception as e:
                print(f"âŒ {cluster_type} è·å–å¤±è´¥: {e}")

    except Exception as e:
        print(f"âŒ æ— æ³•å¯¼å…¥ metrics_collector: {e}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("Overview API çœŸå®æ•°æ®æµ‹è¯•")
    print("=" * 60)

    # 1. æµ‹è¯•Overview APIç«¯ç‚¹
    test_overview_endpoints()

    # 2. æµ‹è¯•åˆ·æ–°åŠŸèƒ½
    test_refresh_endpoint()

    # 3. ç›´æ¥æµ‹è¯•metrics_collector
    asyncio.run(test_direct_metrics())

    print(f"\n{'=' * 60}")
    print("æµ‹è¯•å®Œæˆ!")
    print("\nä¸‹ä¸€æ­¥:")
    print("1. å¦‚æœçœ‹åˆ°å¤§é‡çœŸå®æ•°æ®ï¼Œè¯´æ˜ç³»ç»Ÿæ­£å¸¸å·¥ä½œ")
    print("2. å¦‚æœä»æœ‰æ¨¡æ‹Ÿæ•°æ®ï¼Œè¯·æ£€æŸ¥é›†ç¾¤è¿æ¥")
    print("3. æŸ¥çœ‹FastAPIæ—¥å¿—è·å–æ›´å¤šè°ƒè¯•ä¿¡æ¯")


if __name__ == "__main__":
    main()