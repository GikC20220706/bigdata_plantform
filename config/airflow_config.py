"""
Airflowé›†æˆé…ç½®
é…ç½®Airflowä¸æ•°æ®åº•åº§çš„é›†æˆå‚æ•°
"""

import os
from pathlib import Path
from pydantic import BaseSettings, Field
from typing import Optional, Dict, Any


class AirflowConfig(BaseSettings):
    """Airflowé›†æˆé…ç½®ç±»"""

    # Airflowè¿æ¥é…ç½®
    AIRFLOW_HOST: str = Field(default="airflow-webserver", env="AIRFLOW_HOST")
    AIRFLOW_PORT: int = Field(default=8080, env="AIRFLOW_PORT")
    AIRFLOW_USERNAME: str = Field(default="admin", env="AIRFLOW_USERNAME")
    AIRFLOW_PASSWORD: str = Field(default="admin", env="AIRFLOW_PASSWORD")
    AIRFLOW_API_VERSION: str = Field(default="v1", env="AIRFLOW_API_VERSION")

    # Airflowæ•°æ®åº“é…ç½®ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„MySQLï¼‰
    AIRFLOW_DB_HOST: str = Field(default="mysql", env="AIRFLOW_DB_HOST")
    AIRFLOW_DB_PORT: int = Field(default=3306, env="AIRFLOW_DB_PORT")
    AIRFLOW_DB_USER: str = Field(default="airflow", env="AIRFLOW_DB_USER")
    AIRFLOW_DB_PASSWORD: str = Field(default="airflow123", env="AIRFLOW_DB_PASSWORD")
    AIRFLOW_DB_NAME: str = Field(default="airflow_db", env="AIRFLOW_DB_NAME")

    # Airflow Web UIé…ç½®
    AIRFLOW_WEB_URL: str = Field(default="http://airflow-webserver:8080", env="AIRFLOW_WEB_URL")

    # DAGé…ç½®
    DAG_FOLDER: str = Field(default="./airflow/dags", env="DAG_FOLDER")
    DAG_TEMPLATES_FOLDER: str = Field(default="./airflow/dag_templates", env="DAG_TEMPLATES_FOLDER")

    # ä»»åŠ¡æ‰§è¡Œé…ç½®
    DEFAULT_TASK_TIMEOUT: int = Field(default=3600, env="DEFAULT_TASK_TIMEOUT")  # 1å°æ—¶
    DEFAULT_RETRY_COUNT: int = Field(default=3, env="DEFAULT_RETRY_COUNT")
    DEFAULT_RETRY_DELAY: int = Field(default=300, env="DEFAULT_RETRY_DELAY")  # 5åˆ†é’Ÿ

    # DataXé…ç½®
    DATAX_HOME: str = Field(default="/opt/datax", env="DATAX_HOME")
    DATAX_JOB_PATH: str = Field(default="./datax/jobs", env="DATAX_JOB_PATH")
    DATAX_LOG_PATH: str = Field(default="./datax/logs", env="DATAX_LOG_PATH")

    # SQLæ‰§è¡Œé…ç½®
    SQL_SCRIPTS_PATH: str = Field(default="./scripts/sql", env="SQL_SCRIPTS_PATH")
    SHELL_SCRIPTS_PATH: str = Field(default="./scripts/shell", env="SHELL_SCRIPTS_PATH")

    # æ•°æ®åº•åº§APIé…ç½®
    BIGDATA_PLATFORM_API: str = Field(default="http://bigdata-platform:8000", env="BIGDATA_PLATFORM_API")
    BIGDATA_PLATFORM_AUTH_TOKEN: Optional[str] = Field(default=None, env="BIGDATA_PLATFORM_AUTH_TOKEN")

    # ä»»åŠ¡åˆ†ç±»é…ç½®
    TASK_CATEGORIES = {
        "etl": {
            "display_name": "ETLæ•°æ®å¤„ç†",
            "color": "#1890ff",
            "icon": "âš™ï¸"
        },
        "sync": {
            "display_name": "æ•°æ®åŒæ­¥",
            "color": "#52c41a",
            "icon": "ğŸ”„"
        },
        "sql": {
            "display_name": "SQLæŸ¥è¯¢",
            "color": "#722ed1",
            "icon": "ğŸ—ƒï¸"
        },
        "shell": {
            "display_name": "Shellè„šæœ¬",
            "color": "#fa541c",
            "icon": "ğŸš"
        },
        "datax": {
            "display_name": "DataXä»»åŠ¡",
            "color": "#13c2c2",
            "icon": "ğŸ“Š"
        }
    }

    # DAGé»˜è®¤å‚æ•°
    DEFAULT_DAG_ARGS = {
        'owner': 'bigdata-platform',
        'depends_on_past': False,
        'email_on_failure': True,
        'email_on_retry': False,
        'retries': 3,
        'retry_delay_seconds': 300,
        'max_active_tasks': 16,
        'max_active_runs': 1
    }

    # è°ƒåº¦å™¨é…ç½®
    SCHEDULER_HEARTBEAT_SEC: int = Field(default=5, env="SCHEDULER_HEARTBEAT_SEC")
    SCHEDULER_MAX_THREADS: int = Field(default=2, env="SCHEDULER_MAX_THREADS")

    # æ—¥å¿—é…ç½®
    ENABLE_TASK_LOGS: bool = Field(default=True, env="ENABLE_TASK_LOGS")
    LOG_RETENTION_DAYS: int = Field(default=30, env="LOG_RETENTION_DAYS")

    @property
    def airflow_api_url(self) -> str:
        """Airflow APIåŸºç¡€URL"""
        return f"http://{self.AIRFLOW_HOST}:{self.AIRFLOW_PORT}/api/{self.AIRFLOW_API_VERSION}"

    @property
    def airflow_db_url(self) -> str:
        """Airflowæ•°æ®åº“è¿æ¥URL"""
        return f"mysql+pymysql://{self.AIRFLOW_DB_USER}:{self.AIRFLOW_DB_PASSWORD}@{self.AIRFLOW_DB_HOST}:{self.AIRFLOW_DB_PORT}/{self.AIRFLOW_DB_NAME}?charset=utf8mb4"

    @property
    def auth_headers(self) -> Dict[str, str]:
        """APIè®¤è¯å¤´"""
        import base64
        credentials = f"{self.AIRFLOW_USERNAME}:{self.AIRFLOW_PASSWORD}"
        encoded_credentials = base64.b64encode(credentials.encode()).decode()
        return {
            "Authorization": f"Basic {encoded_credentials}",
            "Content-Type": "application/json"
        }

    def ensure_directories(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        directories = [
            self.DAG_FOLDER,
            self.DAG_TEMPLATES_FOLDER,
            self.DATAX_JOB_PATH,
            self.DATAX_LOG_PATH,
            self.SQL_SCRIPTS_PATH,
            self.SHELL_SCRIPTS_PATH,
            f"{self.DAG_FOLDER}/generated",  # åŠ¨æ€ç”Ÿæˆçš„DAGç›®å½•
            "./airflow/logs",
            "./airflow/config",
            "./airflow/plugins"
        ]

        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"


# åˆ›å»ºå…¨å±€é…ç½®å®ä¾‹
airflow_config = AirflowConfig()

# ç¡®ä¿ç›®å½•å­˜åœ¨
airflow_config.ensure_directories()