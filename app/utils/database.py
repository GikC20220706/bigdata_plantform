"""
Database utilities and connection management for the Big Data Platform.
æ”¯æŒMySQLå’ŒSQLiteæ•°æ®åº“
"""

from typing import Generator

from loguru import logger
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.pool import QueuePool
from config.settings import settings


# æ ¹æ®æ•°æ®åº“ç±»å‹é…ç½®è¿æ¥å‚æ•°
def get_engine_config():
    """æ ¹æ®æ•°æ®åº“ç±»å‹è·å–å¼•æ“é…ç½®"""
    config = {
        "echo": settings.DATABASE_ECHO,
        "pool_pre_ping": settings.DATABASE_POOL_PRE_PING,
    }

    if settings.is_mysql:
        # MySQLé…ç½®
        config.update({
            "poolclass": QueuePool,
            "pool_size": settings.DATABASE_POOL_SIZE,
            "max_overflow": settings.DATABASE_POOL_SIZE * 2,
            "pool_recycle": settings.DATABASE_POOL_RECYCLE,
            "pool_timeout": 30,
            "connect_args": {
                "charset": "utf8mb4",
                "autocommit": False,
            }
        })
    elif settings.is_sqlite:
        # SQLiteé…ç½®
        config.update({
            "connect_args": {"check_same_thread": False}
        })

    return config


def get_sync_db_session():
    """è·å–åŒæ­¥æ•°æ®åº“ä¼šè¯ - ç”¨äºéå¼‚æ­¥ä¸Šä¸‹æ–‡"""
    from sqlalchemy import create_engine
    from sqlalchemy.orm import sessionmaker
    from config.settings import settings

    # åˆ›å»ºåŒæ­¥å¼•æ“
    sync_engine = create_engine(
        settings.DATABASE_URL.replace('+aiomysql', '+pymysql'),  # ä½¿ç”¨pymysqlæ›¿ä»£aiomysql
        pool_pre_ping=True,
        pool_recycle=300,
        echo=False
    )

    # åˆ›å»ºä¼šè¯
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=sync_engine)
    return SessionLocal()

# åˆ›å»ºæ•°æ®åº“å¼•æ“
engine_config = get_engine_config()
engine = create_engine(settings.DATABASE_URL, **engine_config)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()


def get_db() -> Generator[Session, None, None]:
    """
    Get database session.

    Yields:
        Session: Database session
    """
    db = SessionLocal()
    try:
        yield db
        db.commit()
    except Exception:
        db.rollback()
        raise
    finally:
        db.close()


def create_tables():
    """Create all database tables."""
    try:
        # ğŸ”§ ä¿®å¤ï¼šå¯¼å…¥æ‰€æœ‰æ¨¡å‹ä»¥ç¡®ä¿å®ƒä»¬è¢«æ³¨å†Œ
        from app.models import (
            Base,  # ç¡®ä¿å¯¼å…¥Base
            Cluster, ClusterNode, ClusterMetric,
            DataSource, DataSourceConnection,
            TaskDefinition, TaskExecution, TaskSchedule,
            BusinessSystem, BusinessSystemDataSource  # æ·»åŠ ä¸šåŠ¡ç³»ç»Ÿæ¨¡å‹
        )

        # ğŸ”§ æ·»åŠ è°ƒè¯•ä¿¡æ¯
        logger.info("æ­£åœ¨åˆ›å»ºæ•°æ®åº“è¡¨...")
        logger.info(f"å‘ç° {len(Base.metadata.tables)} ä¸ªè¡¨éœ€è¦åˆ›å»º")

        # åˆ›å»ºæ‰€æœ‰è¡¨
        Base.metadata.create_all(bind=engine)

        # ğŸ”§ éªŒè¯è¡¨æ˜¯å¦åˆ›å»ºæˆåŠŸ
        with engine.connect() as conn:
            if settings.is_mysql:
                result = conn.execute("SHOW TABLES")
                tables = [row[0] for row in result.fetchall()]
                logger.info(f"âœ… æˆåŠŸåˆ›å»º {len(tables)} ä¸ªè¡¨: {tables}")
            else:
                result = conn.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [row[0] for row in result.fetchall()]
                logger.info(f"âœ… æˆåŠŸåˆ›å»º {len(tables)} ä¸ªè¡¨: {tables}")

        # å¦‚æœæ˜¯MySQLï¼Œåˆ›å»ºç´¢å¼•
        if settings.is_mysql:
            create_mysql_indexes()

    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“è¡¨å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise


def create_mysql_indexes():
    """ä¸ºMySQLåˆ›å»ºé¢å¤–çš„ç´¢å¼•"""
    try:
        with engine.connect() as conn:
            # æ•°æ®æºè¿æ¥è¡¨çš„å¤åˆç´¢å¼•
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_data_source_connections_source_time 
                ON data_source_connections(data_source_id, connection_timestamp)
            """)

            # é›†ç¾¤æŒ‡æ ‡è¡¨çš„æ—¶é—´ç´¢å¼•
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_cluster_metrics_time 
                ON cluster_metrics(metric_timestamp DESC)
            """)

            # ä»»åŠ¡æ‰§è¡Œè¡¨çš„å¤åˆç´¢å¼•
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_task_executions_def_time 
                ON task_executions(task_definition_id, started_at DESC)
            """)

        print("âœ… MySQL indexes created successfully")
    except Exception as e:
        print(f"âš ï¸ Failed to create MySQL indexes: {e}")


def drop_tables():
    """Drop all database tables."""
    Base.metadata.drop_all(bind=engine)


def test_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        with engine.connect() as conn:
            if settings.is_mysql:
                result = conn.execute("SELECT VERSION() as version")
                version = result.fetchone()[0]
                print(f"âœ… MySQL connection successful - Version: {version}")
            else:
                result = conn.execute("SELECT sqlite_version() as version")
                version = result.fetchone()[0]
                print(f"âœ… SQLite connection successful - Version: {version}")
        return True
    except Exception as e:
        print(f"âŒ Database connection failed: {e}")
        return False


# å¼‚æ­¥æ•°æ®åº“æ”¯æŒï¼ˆå¯é€‰ï¼‰
def create_async_engine():
    """åˆ›å»ºå¼‚æ­¥æ•°æ®åº“å¼•æ“ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
    try:
        from sqlalchemy.ext.asyncio import create_async_engine as create_async_engine_sqlalchemy

        # å°†åŒæ­¥URLè½¬æ¢ä¸ºå¼‚æ­¥URL
        async_url = settings.DATABASE_URL.replace("mysql+pymysql://", "mysql+aiomysql://")

        return create_async_engine_sqlalchemy(
            async_url,
            echo=settings.DATABASE_ECHO,
            pool_size=settings.DATABASE_POOL_SIZE,
            max_overflow=settings.DATABASE_POOL_SIZE * 2,
            pool_recycle=settings.DATABASE_POOL_RECYCLE,
        )
    except ImportError:
        print("âš ï¸ Async database dependencies not installed")
        return None