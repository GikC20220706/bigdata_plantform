"""
ä½œä¸šService - ä¸šåŠ¡é€»è¾‘å±‚
"""
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_, or_, func, desc
from loguru import logger

from app.models.job_work import JobWork, JobWorkType, JobWorkStatus
from app.models.job_workflow import JobWorkflow
from app.schemas.job_workflow import (
    JobWorkCreate, JobWorkUpdate, JobWorkPageQuery, JobWorkCopy
)


class JobWorkService:
    """ä½œä¸šæœåŠ¡"""

    # ä½œä¸šç±»å‹åˆ°æ‰§è¡Œå™¨çš„æ˜ å°„
    WORK_TYPE_EXECUTOR_MAP = {
        JobWorkType.EXE_JDBC: 'jdbc_executor_enhanced',
        JobWorkType.QUERY_JDBC: 'jdbc_executor_enhanced',
        JobWorkType.SPARK_SQL: 'spark_sql_executor',
        JobWorkType.DATA_SYNC_JDBC: 'smart_sync_executor',
        JobWorkType.EXCEL_SYNC_JDBC: 'excel_sync_executor',
        JobWorkType.DB_MIGRATE: 'db_migrate_executor',
        JobWorkType.BASH: 'bash_executor',
        JobWorkType.PYTHON: 'python_executor',
        JobWorkType.CURL: 'http_executor',
        JobWorkType.API: 'api_executor',
        JobWorkType.SPARK_JAR: 'spark_jar_executor',
        JobWorkType.FLINK_SQL: 'flink_sql_executor',
        JobWorkType.FLINK_JAR: 'flink_jar_executor',
    }

    # ==================== ä½œä¸šCRUD ====================

    async def create_work(
            self,
            db: AsyncSession,
            data: JobWorkCreate
    ) -> Dict[str, Any]:
        """åˆ›å»ºä½œä¸š"""
        try:
            # éªŒè¯ä½œä¸šæµæ˜¯å¦å­˜åœ¨
            workflow_result = await db.execute(
                select(JobWorkflow).where(JobWorkflow.id == data.workflowId)
            )
            workflow = workflow_result.scalar_one_or_none()
            if not workflow:
                raise ValueError(f"ä½œä¸šæµä¸å­˜åœ¨: {data.workflowId}")

            # ç¡®å®šæ‰§è¡Œå™¨
            try:
                work_type_enum = JobWorkType(data.workType)
                executor = self.WORK_TYPE_EXECUTOR_MAP.get(work_type_enum)
            except ValueError:
                raise ValueError(f"ä¸æ”¯æŒçš„ä½œä¸šç±»å‹: {data.workType}")

            initial_config = {}

            # JDBCç±»ä½œä¸šï¼šä¿å­˜æ•°æ®æºID
            if work_type_enum in [JobWorkType.EXE_JDBC, JobWorkType.QUERY_JDBC]:
                if data.datasourceId:
                    initial_config = {
                        "dataSourceId": data.datasourceId,
                        "sql": "",
                        "timeout": 300,
                        "type": "execute" if work_type_enum == JobWorkType.EXE_JDBC else "query"
                    }
                    logger.info(f"åˆå§‹åŒ–JDBCä½œä¸šé…ç½®: dataSourceId={data.datasourceId}")
                else:
                    logger.warning(f"åˆ›å»ºJDBCä½œä¸šä½†æœªæŒ‡å®šæ•°æ®æºID")

            # Spark/Flink SQLï¼šä¿å­˜é›†ç¾¤ä¿¡æ¯
            elif work_type_enum in [JobWorkType.SPARK_SQL, JobWorkType.FLINK_SQL]:
                if data.clusterId or data.containerId:
                    initial_config = {
                        "clusterId": data.clusterId,
                        "containerId": data.containerId,
                        "sql": ""
                    }

            # Bash/Pythonï¼šåŸºç¡€é…ç½®
            elif work_type_enum in [JobWorkType.BASH, JobWorkType.PYTHON]:
                initial_config = {
                    "script": "",
                    "timeout": 300
                }

            # HTTP/APIï¼šåŸºç¡€é…ç½®
            elif work_type_enum in [JobWorkType.CURL, JobWorkType.API]:
                initial_config = {
                    "url": "",
                    "method": "GET",
                    "timeout": 60
                }

            # åˆ›å»ºä½œä¸š
            work = JobWork(
                workflow_id=data.workflowId,
                name=data.name,
                work_type=work_type_enum,
                remark=data.remark,
                status=JobWorkStatus.DRAFT,
                executor=executor,
                config=initial_config  # âœ… ä½¿ç”¨åˆå§‹åŒ–çš„é…ç½®
            )

            db.add(work)
            await db.commit()
            await db.refresh(work)

            logger.info(
                f"åˆ›å»ºä½œä¸šæˆåŠŸ: {work.name} (ID: {work.id}, Type: {work.work_type}, "
                f"Config: {initial_config})"
            )

            return {
                "workId": work.id,
                "name": work.name
            }

        except Exception as e:
            await db.rollback()
            logger.error(f"åˆ›å»ºä½œä¸šå¤±è´¥: {e}")
            raise

    async def get_work_by_id(
            self,
            db: AsyncSession,
            work_id: int
    ) -> Optional[JobWork]:
        """æ ¹æ®IDè·å–ä½œä¸š"""
        try:
            result = await db.execute(
                select(JobWork).where(JobWork.id == work_id)
            )
            return result.scalar_one_or_none()

        except Exception as e:
            logger.error(f"è·å–ä½œä¸šå¤±è´¥: {e}")
            raise

    async def page_works(
            self,
            db: AsyncSession,
            query_params: JobWorkPageQuery
    ) -> Dict[str, Any]:
        """åˆ†é¡µæŸ¥è¯¢ä½œä¸š"""
        try:
            # æ„å»ºæŸ¥è¯¢
            query = select(JobWork).where(JobWork.workflow_id == query_params.workflowId)
            count_query = select(func.count(JobWork.id)).where(
                JobWork.workflow_id == query_params.workflowId
            )

            # å…³é”®è¯æœç´¢
            if query_params.searchKeyWord:
                keyword = f"%{query_params.searchKeyWord}%"
                query = query.where(
                    or_(
                        JobWork.name.like(keyword),
                        JobWork.remark.like(keyword)
                    )
                )
                count_query = count_query.where(
                    or_(
                        JobWork.name.like(keyword),
                        JobWork.remark.like(keyword)
                    )
                )

            # è·å–æ€»æ•°
            total_result = await db.execute(count_query)
            total = total_result.scalar()

            # åˆ†é¡µ
            offset = query_params.page * query_params.pageSize
            query = query.order_by(desc(JobWork.created_at))
            query = query.offset(offset).limit(query_params.pageSize)

            # æ‰§è¡ŒæŸ¥è¯¢
            result = await db.execute(query)
            works = result.scalars().all()

            return {
                "content": works,
                "total": total,
                "page": query_params.page,
                "pageSize": query_params.pageSize
            }

        except Exception as e:
            logger.error(f"åˆ†é¡µæŸ¥è¯¢ä½œä¸šå¤±è´¥: {e}")
            raise

    async def update_work(
            self,
            db: AsyncSession,
            data: JobWorkUpdate
    ) -> Optional[JobWork]:
        """æ›´æ–°ä½œä¸š"""
        try:
            work = await self.get_work_by_id(db, data.workId)
            if not work:
                return None

            if data.name is not None:
                work.name = data.name
            if data.remark is not None:
                work.remark = data.remark

            await db.commit()
            await db.refresh(work)

            logger.info(f"æ›´æ–°ä½œä¸šæˆåŠŸ: {work.name} (ID: {work.id})")
            return work

        except Exception as e:
            await db.rollback()
            logger.error(f"æ›´æ–°ä½œä¸šå¤±è´¥: {e}")
            raise

    async def delete_work(
            self,
            db: AsyncSession,
            work_id: int
    ) -> bool:
        """åˆ é™¤ä½œä¸š"""
        try:
            work = await self.get_work_by_id(db, work_id)
            if not work:
                return False

            await db.delete(work)
            await db.commit()

            logger.info(f"åˆ é™¤ä½œä¸šæˆåŠŸ: ID={work_id}")
            return True

        except Exception as e:
            await db.rollback()
            logger.error(f"åˆ é™¤ä½œä¸šå¤±è´¥: {e}")
            raise

    async def copy_work(
            self,
            db: AsyncSession,
            data: JobWorkCopy
    ) -> Dict[str, Any]:
        """å¤åˆ¶ä½œä¸š"""
        try:
            # è·å–æºä½œä¸š
            source_work = await self.get_work_by_id(db, data.workId)
            if not source_work:
                raise ValueError(f"æºä½œä¸šä¸å­˜åœ¨: {data.workId}")

            # åˆ›å»ºæ–°ä½œä¸š
            new_work = JobWork(
                workflow_id=source_work.workflow_id,
                name=data.name,
                work_type=source_work.work_type,
                remark=source_work.remark,
                status=JobWorkStatus.DRAFT,
                executor=source_work.executor,
                config=source_work.config  # å¤åˆ¶é…ç½®
            )

            db.add(new_work)
            await db.commit()
            await db.refresh(new_work)

            logger.info(f"å¤åˆ¶ä½œä¸šæˆåŠŸ: {new_work.name} (æºID: {data.workId}, æ–°ID: {new_work.id})")

            return {
                "workId": new_work.id,
                "name": new_work.name
            }

        except Exception as e:
            await db.rollback()
            logger.error(f"å¤åˆ¶ä½œä¸šå¤±è´¥: {e}")
            raise

    # ==================== ä½œä¸šé…ç½® ====================

    async def save_work_config(
            self,
            db: AsyncSession,
            work_id: int,
            new_config: Dict[str, Any]
    ) -> Optional[JobWork]:
        """ä¿å­˜ä½œä¸šé…ç½®ï¼ˆæ™ºèƒ½åˆå¹¶ï¼‰"""
        try:
            work = await self.get_work_by_id(db, work_id)
            if not work:
                return None

            # è·å–åŸé…ç½®
            old_config = work.config or {}

            # ğŸ†• æ™ºèƒ½åˆå¹¶é…ç½®
            # å¯¹äºSQLç±»ä½œä¸šï¼Œä¿ç•™dataSourceIdç­‰åˆ›å»ºæ—¶çš„é…ç½®
            if work.work_type in [JobWorkType.EXE_JDBC, JobWorkType.QUERY_JDBC]:
                # ä¿ç•™åˆ›å»ºæ—¶çš„dataSourceId
                if 'dataSourceId' in old_config and 'dataSourceId' not in new_config:
                    new_config['dataSourceId'] = old_config['dataSourceId']

                # ç¡®ä¿æœ‰é»˜è®¤å€¼
                if 'timeout' not in new_config:
                    new_config['timeout'] = 300
                if 'type' not in new_config:
                    new_config['type'] = 'execute' if work.work_type == JobWorkType.EXE_JDBC else 'query'

            # å¯¹äºSpark/Flink SQLï¼Œä¿ç•™é›†ç¾¤é…ç½®
            elif work.work_type in [JobWorkType.SPARK_SQL, JobWorkType.FLINK_SQL]:
                for key in ['clusterId', 'containerId', 'sparkConfig', 'flinkConfig']:
                    if key in old_config and key not in new_config:
                        new_config[key] = old_config[key]

            # æ›´æ–°é…ç½®
            work.config = new_config

            await db.commit()
            await db.refresh(work)

            logger.info(f"ä¿å­˜ä½œä¸šé…ç½®æˆåŠŸ: {work.name} (ID: {work.id})")
            return work

        except Exception as e:
            await db.rollback()
            logger.error(f"ä¿å­˜ä½œä¸šé…ç½®å¤±è´¥: {e}")
            raise

    async def get_work_config(
            self,
            db: AsyncSession,
            work_id: int
    ) -> Optional[Dict[str, Any]]:
        """è·å–ä½œä¸šé…ç½®"""
        try:
            work = await self.get_work_by_id(db, work_id)
            if not work:
                return None

            return {
                "id": work.id,
                "name": work.name,
                "workType": work.work_type.value,
                "remark": work.remark,
                "status": work.status.value,
                "config": work.config or {},
                "createDateTime": work.created_at.isoformat() if work.created_at else None,
                "updateDateTime": work.updated_at.isoformat() if work.updated_at else None
            }

        except Exception as e:
            logger.error(f"è·å–ä½œä¸šé…ç½®å¤±è´¥: {e}")
            raise

    # ==================== ä½œä¸šçŠ¶æ€ç®¡ç† ====================

    async def publish_work(
            self,
            db: AsyncSession,
            work_id: int
    ) -> Optional[JobWork]:
        """å‘å¸ƒä½œä¸š"""
        try:
            work = await self.get_work_by_id(db, work_id)
            if not work:
                return None

            work.status = JobWorkStatus.ONLINE
            await db.commit()
            await db.refresh(work)

            logger.info(f"å‘å¸ƒä½œä¸šæˆåŠŸ: {work.name}")
            return work

        except Exception as e:
            await db.rollback()
            logger.error(f"å‘å¸ƒä½œä¸šå¤±è´¥: {e}")
            raise

    async def offline_work(
            self,
            db: AsyncSession,
            work_id: int
    ) -> Optional[JobWork]:
        """ä¸‹çº¿ä½œä¸š"""
        try:
            work = await self.get_work_by_id(db, work_id)
            if not work:
                return None

            work.status = JobWorkStatus.OFFLINE
            await db.commit()
            await db.refresh(work)

            logger.info(f"ä¸‹çº¿ä½œä¸šæˆåŠŸ: {work.name}")
            return work

        except Exception as e:
            await db.rollback()
            logger.error(f"ä¸‹çº¿ä½œä¸šå¤±è´¥: {e}")
            raise


# åˆ›å»ºå…¨å±€å®ä¾‹
job_work_service = JobWorkService()