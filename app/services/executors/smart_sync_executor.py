"""
æ•°æ®åŒæ­¥æ‰§è¡Œå™¨ - å¯¹æ¥smart-syncç³»ç»Ÿ
"""
from typing import Dict, Any, Optional

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from loguru import logger

from .base_executor import JobExecutor
from app.services.data_sync_adapter_service import data_sync_adapter_service


class SmartSyncExecutor(JobExecutor):
    """æ•°æ®åŒæ­¥æ‰§è¡Œå™¨ - å¤ç”¨smart-sync"""

    def __init__(self):
        super().__init__("smart_sync_executor")

    async def execute(
            self,
            db: AsyncSession,
            work_config: Dict[str, Any],
            instance_id: str,
            context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œæ•°æ®åŒæ­¥ä½œä¸š"""
        try:
            logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®åŒæ­¥: {instance_id}")
            logger.info(f"ğŸ“‹ é…ç½®: {work_config}")

            # 1. æŸ¥è¯¢æ•°æ®æºä¿¡æ¯
            from app.models.data_source import DataSource
            from sqlalchemy import select
            import os

            source_result = await db.execute(
                select(DataSource).where(DataSource.id == work_config['sourceId'])
            )
            source_ds = source_result.scalar_one_or_none()

            target_result = await db.execute(
                select(DataSource).where(DataSource.id == work_config['targetId'])
            )
            target_ds = target_result.scalar_one_or_none()

            if not source_ds or not target_ds:
                raise ValueError("æºæˆ–ç›®æ ‡æ•°æ®æºä¸å­˜åœ¨")

            # ä» connection_config ä¸­æå–é…ç½®
            source_conn_config = source_ds.connection_config or {}
            target_conn_config = target_ds.connection_config or {}

            # 2. æ„å»ºæºé…ç½®
            source_config = {
                'type': source_ds.source_type.lower(),
                'name': source_ds.name,
                'table': work_config['sourceTable'],
                'columns': [col['code'] for col in work_config.get('sourceColumns', [])],
                'where': work_config.get('whereCondition', '')
            }

            # MySQL/PostgreSQLç­‰éœ€è¦è¿æ¥ä¿¡æ¯
            if source_ds.source_type.lower() in ['mysql', 'postgresql', 'kingbase']:
                source_config.update({
                    'host': source_conn_config.get('host'),
                    'port': source_conn_config.get('port', 3306),
                    'database': source_conn_config.get('database'),
                    'username': source_conn_config.get('username'),
                    'password': source_conn_config.get('password')
                })

            # 3. æ„å»ºç›®æ ‡é…ç½®
            target_config = {
                'type': target_ds.source_type.lower(),
                'name': target_ds.name,
                'table': work_config['targetTable'],
                'columns': [col['code'] for col in work_config.get('targetColumns', [])]
            }

            # âœ… Hive ç‰¹æ®Šå¤„ç†
            if target_ds.source_type.lower() == 'hive':
                # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®ä¸­è·å– Hive ç›¸å…³ä¿¡æ¯
                namenode_host = os.getenv('HIVE_SERVER_HOST', '192.142.76.242')
                namenode_port = os.getenv('HADOOP_NAMENODE_PORT', '8020')
                database = target_conn_config.get('database', 'default')

                # ç”Ÿæˆå½“å‰æ—¥æœŸåˆ†åŒº
                from datetime import datetime
                current_date = datetime.now().strftime('%Y-%m-%d')

                # ç”Ÿæˆ HDFS è·¯å¾„
                base_path = '/user/hive/warehouse'
                table_name = work_config['targetTable']

                if database and database != 'default':
                    hdfs_path = f"{base_path}/{database}.db/{table_name}/dt={current_date}"
                else:
                    hdfs_path = f"{base_path}/{table_name}/dt={current_date}"

                target_config.update({
                    'namenode_host': namenode_host,
                    'namenode_port': namenode_port,
                    'database': database,
                    'hdfs_path': hdfs_path,
                    'file_type': 'orc',
                    'file_name': f'{table_name}_data',
                    'partition_column': 'dt',
                    'partition_value': current_date,
                    'compression': 'snappy'
                })

                logger.info(f"âœ… Hiveé…ç½®: namenode={namenode_host}:{namenode_port}")
                logger.info(f"âœ… HDFSè·¯å¾„: {hdfs_path}")

            else:
                # MySQL/PostgreSQLç­‰
                target_config.update({
                    'host': target_conn_config.get('host'),
                    'port': target_conn_config.get('port', 3306),
                    'database': target_conn_config.get('database'),
                    'username': target_conn_config.get('username'),
                    'password': target_conn_config.get('password')
                })

            # 4. æ„å»º DataX é…ç½®
            from app.services.datax_service import DataXIntegrationService
            datax_service = DataXIntegrationService()

            sync_config = {
                'task_id': instance_id,
                'source': source_config,
                'target': target_config,
                'column_mapping': work_config.get('columnMapping', []),
                'sync_mode': work_config.get('syncMode', 'replace')
            }

            logger.info(f"ğŸ“¦ DataXé…ç½®æ„å»ºå®Œæˆ")

            # 5. æ‰§è¡ŒåŒæ­¥
            result = await datax_service.create_sync_task(sync_config)

            if result.get('success'):
                return {
                    "success": True,
                    "message": "æ•°æ®åŒæ­¥æˆåŠŸ",
                    "data": result,
                    "error": None
                }
            else:
                return {
                    "success": False,
                    "message": "æ•°æ®åŒæ­¥å¤±è´¥",
                    "data": None,
                    "error": result.get('error')
                }

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŒæ­¥æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {
                "success": False,
                "message": "åŒæ­¥å¤±è´¥",
                "data": None,
                "error": str(e)
            }

    async def validate_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯é…ç½®"""
        errors = []

        if not config.get('sourceDBId'):
            errors.append("ç¼ºå°‘sourceDBId")

        if not config.get('targetDBId'):
            errors.append("ç¼ºå°‘targetDBId")

        sync_mode = config.get('syncMode', 'single')

        if sync_mode == 'single':
            if not config.get('sourceTable'):
                errors.append("ç¼ºå°‘sourceTable")
            if not config.get('targetTable'):
                errors.append("ç¼ºå°‘targetTable")
        elif sync_mode == 'multi':
            tables = config.get('tables', [])
            if not tables:
                errors.append("å¤šè¡¨åŒæ­¥æ¨¡å¼ä¸‹ç¼ºå°‘tablesé…ç½®")
            else:
                for i, table in enumerate(tables):
                    if not table.get('sourceTable'):
                        errors.append(f"è¡¨{i + 1}ç¼ºå°‘sourceTable")
                    if not table.get('targetTable'):
                        errors.append(f"è¡¨{i + 1}ç¼ºå°‘targetTable")
        else:
            errors.append(f"ä¸æ”¯æŒçš„åŒæ­¥æ¨¡å¼: {sync_mode}")

        return {
            "valid": len(errors) == 0,
            "errors": errors
        }